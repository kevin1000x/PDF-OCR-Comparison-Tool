"""
GPUåŠ é€Ÿæµ‹è¯•è„šæœ¬ - ä¿®å¤ç‰ˆ
"""

import torch
import time
import os
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont

def test_gpu_status():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    print("=" * 60)
    print("1ï¸âƒ£  GPUçŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨")
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"   PyTorchå·²åˆ†é…: {allocated:.2f} GB")
        return True
    else:
        print("âŒ CUDAä¸å¯ç”¨ï¼")
        return False

def test_gpu_speed():
    """æµ‹è¯•GPUè®¡ç®—é€Ÿåº¦"""
    print("\n" + "=" * 60)
    print("2ï¸âƒ£  GPU vs CPU é€Ÿåº¦å¯¹æ¯”")
    print("=" * 60)
    
    size = 4000
    print(f"\næµ‹è¯•çŸ©é˜µè¿ç®— ({size}x{size})...")
    
    a_cpu = torch.randn(size, size)
    b_cpu = torch.randn(size, size)
    
    start = time.time()
    for _ in range(3):
        c_cpu = torch.mm(a_cpu, b_cpu)
    cpu_time = (time.time() - start) / 3
    print(f"   CPU: {cpu_time*1000:.1f} ms")
    
    if torch.cuda.is_available():
        a_gpu = a_cpu.cuda()
        b_gpu = b_cpu.cuda()
        
        torch.mm(a_gpu, b_gpu)
        torch.cuda.synchronize()
        
        start = time.time()
        for _ in range(3):
            c_gpu = torch.mm(a_gpu, b_gpu)
            torch.cuda.synchronize()
        gpu_time = (time.time() - start) / 3
        print(f"   GPU: {gpu_time*1000:.1f} ms")
        print(f"   ðŸš€ GPUåŠ é€Ÿ: {cpu_time/gpu_time:.1f}x")
        
        del a_gpu, b_gpu, c_gpu
        torch.cuda.empty_cache()

def test_ocr_speed():
    """æµ‹è¯•DeepSeek-OCR2é€Ÿåº¦"""
    print("\n" + "=" * 60)
    print("3ï¸âƒ£  DeepSeek-OCR2 é€Ÿåº¦æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    img = Image.new('RGB', (1200, 800), 'white')
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype("msyh.ttc", 36)
    except:
        font = ImageFont.load_default()
    
    test_text = """æ·±åœ³å¸‚å—å±±åŒºé«˜æ–°åŒºä¸­åŒºè¥¿ç‰‡åŒºåœ°åŒº
æ›´æ–°å•å…ƒè§„åˆ’
CN07-2024-041/01
æŠ€æœ¯æ–‡ä»¶

é¡¹ç›®æ¦‚å†µ
æœ¬é¡¹ç›®ä½äºŽå—å±±åŒºé«˜æ–°åŒºä¸­åŒºè¥¿ç‰‡åŒºï¼Œæ€»å åœ°é¢ç§¯çº¦5.2å…¬é¡·
è§„åˆ’å»ºç­‘é¢ç§¯çº¦15ä¸‡å¹³æ–¹ç±³ï¼Œå…¶ä¸­ä½å®…çº¦10ä¸‡å¹³æ–¹ç±³
å•†ä¸šé…å¥—çº¦3ä¸‡å¹³æ–¹ç±³ï¼Œå…¬å…±è®¾æ–½çº¦2ä¸‡å¹³æ–¹ç±³"""
    
    draw.text((50, 50), test_text, fill='black', font=font)
    test_path = 'test_ocr_image.png'
    img.save(test_path)
    print(f"   åˆ›å»ºæµ‹è¯•å›¾ç‰‡: {test_path}")
    
    try:
        from deepseek_ocr2_engine import DeepSeekOCR2Engine
        
        print("\n   åŠ è½½OCRå¼•æ“Ž...")
        start = time.time()
        ocr = DeepSeekOCR2Engine()
        load_time = time.time() - start
        print(f"   å¼•æ“Žåˆå§‹åŒ–: {load_time:.2f}s")
        
        # ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å
        print("\n   å¼€å§‹OCRæµ‹è¯•ï¼ˆ3æ¬¡å–å¹³å‡ï¼‰...")
        times = []
        
        for i in range(3):
            start = time.time()
            # ä½¿ç”¨ recognize_image æ–¹æ³•
            results = ocr.recognize_image(test_path)
            elapsed = time.time() - start
            times.append(elapsed)
            
            # æå–æ–‡æœ¬
            if results:
                text = "\n".join([r.text for r in results])
                char_count = len(text)
            else:
                char_count = 0
            
            print(f"   ç¬¬{i+1}æ¬¡: {elapsed:.2f}s (è¯†åˆ«{char_count}å­—ç¬¦)")
        
        avg_time = sum(times) / len(times)
        print(f"\n   â±ï¸  å¹³å‡OCRæ—¶é—´: {avg_time:.2f}s/é¡µ")
        
        # æ˜¾ç¤ºGPUæ˜¾å­˜
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            print(f"   ðŸ“Š GPUæ˜¾å­˜ä½¿ç”¨: {allocated:.2f} GB")
        
        return avg_time
        
    except Exception as e:
        import traceback
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return None
    finally:
        # æ¸…ç†
        if os.path.exists(test_path):
            os.remove(test_path)

def estimate_remaining_time(avg_time):
    """ä¼°ç®—å‰©ä½™æ—¶é—´"""
    print("\n" + "=" * 60)
    print("4ï¸âƒ£  æ—¶é—´ä¼°ç®—")
    print("=" * 60)
    
    if avg_time:
        # å‡è®¾æƒ…å†µ
        scenarios = [
            ("å·²å¤„ç† 334/523 é¡µ", 523 - 334),
            ("å®Œæ•´ 523 é¡µ", 523),
            ("1000 é¡µæ–‡æ¡£", 1000),
        ]
        
        for name, pages in scenarios:
            total_seconds = pages * avg_time
            hours = total_seconds / 3600
            print(f"   {name}: {hours:.1f} å°æ—¶")

def show_current_process():
    """æ˜¾ç¤ºå½“å‰è¿è¡Œçš„Pythonè¿›ç¨‹"""
    print("\n" + "=" * 60)
    print("5ï¸âƒ£  å½“å‰OCRè¿›ç¨‹")
    print("=" * 60)
    
    import subprocess
    result = subprocess.run(
        ['nvidia-smi', '--query-compute-apps=pid,name,used_memory', '--format=csv,noheader'],
        capture_output=True, text=True
    )
    
    for line in result.stdout.strip().split('\n'):
        if 'python' in line.lower():
            print(f"   {line}")

if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("ðŸ” GPUåŠ é€Ÿå®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    gpu_ok = test_gpu_status()
    
    if gpu_ok:
        test_gpu_speed()
        avg_time = test_ocr_speed()
        if avg_time:
            estimate_remaining_time(avg_time)
        show_current_process()
        
        print("\n" + "=" * 60)
        print("ðŸ’¡ ä¼˜åŒ–å»ºè®®")
        print("=" * 60)
        print("""
å¦‚æžœé€Ÿåº¦ä»ç„¶è¾ƒæ…¢ï¼Œå¯ä»¥ï¼š

1. å…³é—­Wallpaper Engineé‡Šæ”¾æ˜¾å­˜
   ä»»åŠ¡æ å³é”® -> é€€å‡º

2. é™ä½ŽDPI (ä¿®æ”¹config.yaml)
   pdf:
     dpi: 150

3. ç¡®ä¿é«˜æ€§èƒ½æ¨¡å¼
   Windowsè®¾ç½® -> ç”µæº -> é«˜æ€§èƒ½
""")
